{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main tutorial notebook. It is intended to introduce the basic machinery and how it is used.\n",
    "\n",
    "First, let's import everything we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "# sys.path.append('.')  # or full path to CompSep\n",
    "np.math = math  # Redirect numpy.math to the built-in math module\n",
    "\n",
    "import denoising\n",
    "import importlib\n",
    "denoising = importlib.reload(denoising)\n",
    "import utils\n",
    "utils = importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import the data. Since this is simulation data of log column density (in units of $1/cm^3$). If the data is already preprocessed, you can just import it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the column density map from file\n",
    "logN_H = np.load('Archive/Turb_3.npy')[1]  \n",
    "# logN_H = utils.downsample_by_four(logN_H)\n",
    "nx, ny = logN_H.shape\n",
    "\n",
    "# Define constant dust temperature\n",
    "T_d = 10  # Typical Planck dust temperature in K\n",
    "\n",
    "# int_val = []\n",
    "# for nu in nu_list:\n",
    "#     int_val.append(np.mean(modified_blackbody(logN_H, T_d, nu*1e9)))\n",
    "# int_val = np.array(int_val)\n",
    "\n",
    "# Observation frequency (e.g., 353 GHz in Hz)\n",
    "\n",
    "# Compute the mock observed intensity map in μK_CMB\n",
    "nu = (217,353)\n",
    "I_nu_map_μK_nu1 = utils.modified_blackbody(logN_H, T_d, nu[0]*1e9)\n",
    "I_nu_map_μK_nu2 = utils.modified_blackbody(logN_H, T_d, nu[1]*1e9)\n",
    "I_nu_map_μK = (I_nu_map_μK_nu1, I_nu_map_μK_nu2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arrays that we work with need to have dimension `(1, H, W)`.\n",
    "\n",
    "Now we define tuples of dust which will be our ground truth $s$, white noise, $n$, and finally cmb $c$. For simplicity the CMB here is modelled as a simple Gaussian random field with a falling power law for the power spectrum.\n",
    "\n",
    "Keep in mind that in general, you can just import your own contamination array, respecting the broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure inputs have shape (1, H, W)\n",
    "dust_nu1 = I_nu_map_μK_nu1[None, :, :]\n",
    "dust_nu2 = I_nu_map_μK_nu2[None, :, :]\n",
    "\n",
    "dust = (dust_nu1, dust_nu2)\n",
    "\n",
    "# --- CMB Parameters ---\n",
    "n_realizations = 100\n",
    "SNR = 1\n",
    "amplitude = 2.\n",
    "spectral_index = -1.7\n",
    "\n",
    "nx, ny = dust_nu1.shape[-2], dust_nu1.shape[-1]\n",
    "\n",
    "# --- Compute noise variances ---\n",
    "variance_nu1 = (np.std(dust_nu1) / SNR) ** 2\n",
    "variance_nu2 = (np.std(dust_nu2) / SNR) ** 2\n",
    "variance = (variance_nu1, variance_nu2)\n",
    "\n",
    "# --- Create contamination_arr with shape (n_realizations, 2, 1, H, W) ---\n",
    "contamination_arr = np.zeros((n_realizations, 2, 1, nx, ny), dtype=np.float32)\n",
    "\n",
    "for i in range(n_realizations):\n",
    "    # Shared CMB: shape (1, H, W)\n",
    "    cmb_map = utils.generate_cmb_map(n_x=nx, n_y=ny, amplitude=amplitude, spectral_index=spectral_index)\n",
    "    cmb_map = cmb_map.cpu().numpy()[None, :, :]\n",
    "\n",
    "    # Independent noise: shape (1, H, W)\n",
    "    noise_nu1 = np.random.normal(0, np.sqrt(variance_nu1), (1, nx, ny))\n",
    "    noise_nu2 = np.random.normal(0, np.sqrt(variance_nu2), (1, nx, ny))\n",
    "\n",
    "    # Total contamination: shape (1, H, W)\n",
    "    contamination_arr[i, 0] = noise_nu1 + cmb_map\n",
    "    contamination_arr[i, 1] = noise_nu2 + cmb_map\n",
    "\n",
    "contamination_arr_nu1 = contamination_arr[:, 0]  # shape: (Mn, 1, H, W)\n",
    "contamination_arr_nu2 = contamination_arr[:, 1]  # shape: (Mn, 1, H, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create our data, given by the equation $d^\\nu = s^\\nu + c + n^\\nu$ for each frequency band $\\nu$. Notice that we are assuming that we can sample configures $c \\sim P(c)$ and $n \\sim P(n)$. While for this case this might be possible, in general for more complicated contaminations this may be more difficult. This is a strong assumption.\n",
    "\n",
    "We assume that $c$ is independent of $\\nu$ because its spectral energy function is that of a perfect black body, and therefore $c^\\nu = B(\\nu, T) c_0$, where $c_0$ is some configuration and all the frequency dependce factors out into the Planck function. Therefore, we can define units (called Kelvin CMB) where this is independent of frequency.\n",
    "\n",
    "The tuple contains the data for two channels, that is, $(d^{\\nu_1}, d^{\\nu_2})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_nu1 = np.random.normal(0, np.sqrt(variance_nu1), dust_nu1.shape)\n",
    "noise_nu2 = np.random.normal(0, np.sqrt(variance_nu2), dust_nu2.shape)\n",
    "\n",
    "noise = (noise_nu1, noise_nu2)\n",
    "\n",
    "cmb_map = utils.generate_cmb_map(n_x=nx, n_y=ny, amplitude=amplitude, spectral_index=spectral_index)\n",
    "cmb_map = cmb_map.cpu().numpy()[None, :, :]\n",
    "\n",
    "data_nu1 = dust_nu1 + noise_nu1 + cmb_map\n",
    "data_nu2 = dust_nu2 + noise_nu2 + cmb_map\n",
    "\n",
    "# define target\n",
    "data = (data_nu1, data_nu2)\n",
    "\n",
    "# target is \n",
    "image_target = data\n",
    "\n",
    "# definte initial maps for optimisation\n",
    "image_init = image_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $x$ is an image, then $\\phi(x)$ denotes a set of summary statistics. For example, if can be the pixel average, and the pixel wide standard deviation. In that case, it would be $\\phi(x) = ( \\mu, \\sigma )$. We are going to work with a different kind of coefficients, called  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholding = True\n",
    "if thresholding:\n",
    "    M, N, J, L = dust_nu1.shape[-2], dust_nu1.shape[-1], 7, 4\n",
    "    st_calc = denoising.Scattering2d(M, N, J, L)\n",
    "    st_calc.add_ref(ref=data_nu1)\n",
    "    s_cov = st_calc.scattering_cov(data_nu1, use_ref=True, \n",
    "                        normalization='P00', pseudo_coef=1\n",
    "                    )\n",
    "    st_calc.add_ref_ab(ref_a=data_nu1, ref_b=data_nu2)\n",
    "    s_cov_2fields = st_calc.scattering_cov_2fields(data_nu1, data_nu2, use_ref=True, \n",
    "                        normalization='P00'\n",
    "                    )\n",
    "    threshold_func = denoising.threshold_func(s_cov)\n",
    "    print(threshold_func)\n",
    "    threshold_func_2fields = denoising.threshold_func(s_cov_2fields, two_fields=True)\n",
    "\n",
    "else:\n",
    "    threshold_func = None\n",
    "    threshold_func_2fields = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: If possible, try to parallelize compute_std in order to do the computation in parallel for each image instead of sequentially. \n",
    "#TODO: Make it compute the mean in addition to the std\n",
    "#TODO: Choose the indices in closure, and then pass the batch directly to the loss function, instead of the full contamination_array, and then choosing within each loss computation.\n",
    "std = denoising.compute_std(image_target, contamination_arr = contamination_arr, s_cov_func = threshold_func)\n",
    "std_double = denoising.compute_std_double(image_target, contamination_arr = contamination_arr, s_cov_func = threshold_func_2fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "whatup\n",
      "# of estimators:  54827\n",
      "whatup\n",
      "whatup\n",
      "whatup\n",
      "whatup\n",
      "whatup\n",
      "whatup\n",
      "whatup\n",
      "whatup\n",
      "whatup\n",
      "whatup\n",
      "whatup\n",
      "whatup\n",
      "whatup\n",
      "whatup\n",
      "whatup\n",
      "whatup\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     running_map \u001b[38;5;241m=\u001b[39m \u001b[43mdenoising\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenoise_double\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontamination_arr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontamination_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd_double\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd_double\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_each_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_cov_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_cov_func_2fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold_func_2fields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     std \u001b[38;5;241m=\u001b[39m denoising\u001b[38;5;241m.\u001b[39mcompute_std(running_map, contamination_arr \u001b[38;5;241m=\u001b[39m contamination_arr, s_cov_func \u001b[38;5;241m=\u001b[39m threshold_func)\n\u001b[1;32m      8\u001b[0m     std_double \u001b[38;5;241m=\u001b[39m denoising\u001b[38;5;241m.\u001b[39mcompute_std_double(running_map, contamination_arr \u001b[38;5;241m=\u001b[39m contamination_arr, s_cov_func \u001b[38;5;241m=\u001b[39m threshold_func_2fields)\n",
      "File \u001b[0;32m~/Desktop/ScatteringDenoising/denoising/__init__.py:399\u001b[0m, in \u001b[0;36mdenoise_double\u001b[0;34m(target, contamination_arr, std, std_double, image_init, n_batch, s_cov_func, s_cov_func_2fields, J, L, M, N, l_oversampling, frequency_factor, optim_algorithm, steps, learning_rate, device, wavelets, seed, if_large_batch, C11_criteria, normalization, precision, print_each_step, pseudo_coef, remove_edge)\u001b[0m\n\u001b[1;32m    395\u001b[0m     squared_norms \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(normalized_diff \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m normalized_diff\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m squared_norms\u001b[38;5;241m.\u001b[39mmean()   \n\u001b[0;32m--> 399\u001b[0m image_syn \u001b[38;5;241m=\u001b[39m \u001b[43mdenoise_general_double\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBR_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m\u001b[49m\u001b[43moptim_algorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim_algorithm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_each_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_each_step\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image_syn\n",
      "File \u001b[0;32m~/Desktop/ScatteringDenoising/denoising/__init__.py:487\u001b[0m, in \u001b[0;36mdenoise_general_double\u001b[0;34m(target, image_init, estimator_function, loss_function, optim_algorithm, steps, learning_rate, device, precision, print_each_step)\u001b[0m\n\u001b[1;32m    485\u001b[0m t_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optim_algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLBFGS\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 487\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n",
      "File \u001b[0;32m~/anaconda3/envs/healpy_env/lib/python3.11/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/healpy_env/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/healpy_env/lib/python3.11/site-packages/torch/optim/lbfgs.py:330\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    327\u001b[0m state\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_iter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# evaluate initial f(x) and df/dx\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m orig_loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(orig_loss)\n\u001b[1;32m    332\u001b[0m current_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/healpy_env/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ScatteringDenoising/denoising/__init__.py:470\u001b[0m, in \u001b[0;36mdenoise_general_double.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    467\u001b[0m synthesized_images \u001b[38;5;241m=\u001b[39m image_model\u001b[38;5;241m.\u001b[39mget_images()\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# Compute the loss using the loss function with all targets and synthesized images\u001b[39;00m\n\u001b[0;32m--> 470\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msynthesized_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# Check for NaN loss\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(loss):\n",
      "File \u001b[0;32m~/Desktop/ScatteringDenoising/denoising/__init__.py:304\u001b[0m, in \u001b[0;36mdenoise_double.<locals>.BR_loss\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    301\u001b[0m targets \u001b[38;5;241m=\u001b[39m args[:mid]\n\u001b[1;32m    302\u001b[0m images \u001b[38;5;241m=\u001b[39m args[mid:]\n\u001b[0;32m--> 304\u001b[0m loss1 \u001b[38;5;241m=\u001b[39m \u001b[43mBR_loss_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontamination_arr\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m loss2 \u001b[38;5;241m=\u001b[39m BR_loss_single(targets[\u001b[38;5;241m1\u001b[39m], images[\u001b[38;5;241m1\u001b[39m], std[\u001b[38;5;241m1\u001b[39m], contamination_arr[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    306\u001b[0m loss3 \u001b[38;5;241m=\u001b[39m BR_loss_double(targets[\u001b[38;5;241m0\u001b[39m], images[\u001b[38;5;241m0\u001b[39m], targets[\u001b[38;5;241m1\u001b[39m], images[\u001b[38;5;241m1\u001b[39m], contamination_arr)\n",
      "File \u001b[0;32m~/Desktop/ScatteringDenoising/denoising/__init__.py:331\u001b[0m, in \u001b[0;36mdenoise_double.<locals>.BR_loss_single\u001b[0;34m(target, image, _std, contamination_arr)\u001b[0m\n\u001b[1;32m    327\u001b[0m cont_images \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m contamination_tensor  \u001b[38;5;66;03m# (n_realizations, 1, H, W)\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Step 3: Compute noisy statistics\u001b[39;00m\n\u001b[1;32m    330\u001b[0m noisy_stats_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[0;32m--> 331\u001b[0m     \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcont_images\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_realizations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m    332\u001b[0m     dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    333\u001b[0m )  \u001b[38;5;66;03m# Shape: (n_realizations, N_coeffs)\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Step 4: Normalize and compute squared norm\u001b[39;00m\n\u001b[1;32m    336\u001b[0m diff \u001b[38;5;241m=\u001b[39m noisy_stats_tensor \u001b[38;5;241m-\u001b[39m target_stats[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n",
      "File \u001b[0;32m~/Desktop/ScatteringDenoising/denoising/__init__.py:331\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    327\u001b[0m cont_images \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m contamination_tensor  \u001b[38;5;66;03m# (n_realizations, 1, H, W)\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# Step 3: Compute noisy statistics\u001b[39;00m\n\u001b[1;32m    330\u001b[0m noisy_stats_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[0;32m--> 331\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcont_images\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_realizations)],\n\u001b[1;32m    332\u001b[0m     dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    333\u001b[0m )  \u001b[38;5;66;03m# Shape: (n_realizations, N_coeffs)\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Step 4: Normalize and compute squared norm\u001b[39;00m\n\u001b[1;32m    336\u001b[0m diff \u001b[38;5;241m=\u001b[39m noisy_stats_tensor \u001b[38;5;241m-\u001b[39m target_stats[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n",
      "File \u001b[0;32m~/Desktop/ScatteringDenoising/denoising/__init__.py:273\u001b[0m, in \u001b[0;36mdenoise_double.<locals>.func\u001b[0;34m(map1, ref_map1, map2, ref_map2)\u001b[0m\n\u001b[1;32m    267\u001b[0m             coeffs \u001b[38;5;241m=\u001b[39m  st_calc\u001b[38;5;241m.\u001b[39mscattering_cov(\n\u001b[1;32m    268\u001b[0m                 x, use_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, if_large_batch\u001b[38;5;241m=\u001b[39mif_large_batch, C11_criteria\u001b[38;5;241m=\u001b[39mC11_criteria, \n\u001b[1;32m    269\u001b[0m                 normalization\u001b[38;5;241m=\u001b[39mnormalization, pseudo_coef\u001b[38;5;241m=\u001b[39mpseudo_coef, remove_edge\u001b[38;5;241m=\u001b[39mremove_edge\n\u001b[1;32m    270\u001b[0m             )\n\u001b[1;32m    271\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m s_cov_func(coeffs)\n\u001b[0;32m--> 273\u001b[0m     coef_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfunc_s\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmap1\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;66;03m# Two-field case\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     st_calc\u001b[38;5;241m.\u001b[39madd_ref_ab(ref_a\u001b[38;5;241m=\u001b[39mref_map1, ref_b\u001b[38;5;241m=\u001b[39mref_map2)\n",
      "File \u001b[0;32m~/Desktop/ScatteringDenoising/denoising/__init__.py:261\u001b[0m, in \u001b[0;36mdenoise_double.<locals>.func.<locals>.func_s\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunc_s\u001b[39m(x):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhatup\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mst_calc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscattering_cov\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_large_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_large_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC11_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mC11_criteria\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpseudo_coef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpseudo_coef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_edge\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_edge\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor_synthesis\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/ScatteringDenoising/denoising/Scattering2d.py:756\u001b[0m, in \u001b[0;36mScattering2d.scattering_cov\u001b[0;34m(self, data, if_large_batch, C11_criteria, use_ref, normalization, remove_edge, pseudo_coef, get_variance)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m remove_edge:\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m if_large_batch:\n\u001b[1;32m    752\u001b[0m         \u001b[38;5;66;03m# [N_image,l1,l2,l3,x,y]\u001b[39;00m\n\u001b[1;32m    753\u001b[0m         C11_pre_norm[:,j1,j2,j3,:,:,:] \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m            \u001b[49m\u001b[43mI1_f_small\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj1\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mM3\u001b[49m\u001b[43m,\u001b[49m\u001b[43mN3\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mI1_f2_wf3_2_small\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN_image\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43mM3\u001b[49m\u001b[43m,\u001b[49m\u001b[43mN3\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 756\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m fft_factor\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    758\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m l1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(L):\n\u001b[1;32m    759\u001b[0m             \u001b[38;5;66;03m# [N_image,l2,l3,x,y]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 3 #number of epochs\n",
    "# decontaminate\n",
    "for i in range(n_epochs):\n",
    "    print(f'Starting epoch {i+1}')\n",
    "    running_map = denoising.denoise_double(image_target, contamination_arr = contamination_arr, std = std, std_double=std_double, seed=0, print_each_step=True, steps = 25, n_batch = 25, s_cov_func=threshold_func, s_cov_func_2fields=threshold_func_2fields)\n",
    "\n",
    "    std = denoising.compute_std(running_map, contamination_arr = contamination_arr, s_cov_func = threshold_func)\n",
    "    std_double = denoising.compute_std_double(running_map, contamination_arr = contamination_arr, s_cov_func = threshold_func_2fields)\n",
    "\n",
    "#TODO change function so that you give it a list of predefined loss functions\n",
    "image_syn_nu1 = running_map[0]\n",
    "image_syn_nu2 = running_map[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tuples to NumPy arrays\n",
    "dust = np.stack([dust_nu1[0], dust_nu2[0]])  # Shape: (2, ...)\n",
    "data = np.stack([data_nu1[0], data_nu2[0]])  # Shape: (2, ...)\n",
    "image_denoised = np.stack([image_syn_nu1[0], image_syn_nu2[0]])  # Ensure it's an array\n",
    "\n",
    "cmb = True\n",
    "# Create an array of objects to preserve different shapes\n",
    "results = np.array([dust, data, image_denoised])\n",
    "np.save(f\"nu={nu}_cmb={cmb}_threshold\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "healpy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
