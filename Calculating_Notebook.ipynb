{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "np.math = math  # Redirect numpy.math to the built-in math module\n",
    "\n",
    "import denoising\n",
    "import importlib\n",
    "denoising = importlib.reload(denoising)\n",
    "import utils\n",
    "utils = importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.constants import h, k, c\n",
    "from astropy import units as u\n",
    "\n",
    "# Load the column density map from file\n",
    "logN_H = np.load('Archive/Turb_3.npy')[1]  \n",
    "# logN_H = utils.downsample_by_four(logN_H)\n",
    "nx, ny = logN_H.shape\n",
    "\n",
    "# Define constant dust temperature\n",
    "T_d = 10  # Typical Planck dust temperature in K\n",
    "\n",
    "# int_val = []\n",
    "# for nu in nu_list:\n",
    "#     int_val.append(np.mean(modified_blackbody(logN_H, T_d, nu*1e9)))\n",
    "# int_val = np.array(int_val)\n",
    "\n",
    "# Observation frequency (e.g., 353 GHz in Hz)\n",
    "\n",
    "# Compute the mock observed intensity map in μK_CMB\n",
    "nu = (217,353)\n",
    "I_nu_map_μK_nu1 = utils.modified_blackbody(logN_H, T_d, nu[0]*1e9)\n",
    "I_nu_map_μK_nu2 = utils.modified_blackbody(logN_H, T_d, nu[1]*1e9)\n",
    "I_nu_map_μK = (I_nu_map_μK_nu1, I_nu_map_μK_nu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure inputs have shape (1, H, W)\n",
    "dust_nu1 = I_nu_map_μK_nu1[None, :, :]\n",
    "dust_nu2 = I_nu_map_μK_nu2[None, :, :]\n",
    "\n",
    "dust = (dust_nu1, dust_nu2)\n",
    "\n",
    "# --- Parameters ---\n",
    "n_realizations = 100\n",
    "SNR = 1\n",
    "amplitude = 2.\n",
    "spectral_index = -1.7\n",
    "\n",
    "nx, ny = dust_nu1.shape[-2], dust_nu1.shape[-1]\n",
    "\n",
    "# --- Compute noise variances ---\n",
    "variance_nu1 = (np.std(dust_nu1) / SNR) ** 2\n",
    "variance_nu2 = (np.std(dust_nu2) / SNR) ** 2\n",
    "variance = (variance_nu1, variance_nu2)\n",
    "\n",
    "# --- Create contamination_arr with shape (n_realizations, 2, 1, H, W) ---\n",
    "contamination_arr = np.zeros((n_realizations, 2, 1, nx, ny), dtype=np.float32)\n",
    "\n",
    "for i in range(n_realizations):\n",
    "    # Shared CMB: shape (1, H, W)\n",
    "    cmb_map = utils.generate_cmb_map(n_x=nx, n_y=ny, amplitude=amplitude, spectral_index=spectral_index)\n",
    "    cmb_map = cmb_map.cpu().numpy()[None, :, :]\n",
    "\n",
    "    # Independent noise: shape (1, H, W)\n",
    "    noise_nu1 = np.random.normal(0, np.sqrt(variance_nu1), (1, nx, ny))\n",
    "    noise_nu2 = np.random.normal(0, np.sqrt(variance_nu2), (1, nx, ny))\n",
    "\n",
    "    # Total contamination: shape (1, H, W)\n",
    "    contamination_arr[i, 0] = noise_nu1 + cmb_map\n",
    "    contamination_arr[i, 1] = noise_nu2 + cmb_map\n",
    "\n",
    "contamination_arr_nu1 = contamination_arr[:, 0]  # shape: (Mn, 1, H, W)\n",
    "contamination_arr_nu2 = contamination_arr[:, 1]  # shape: (Mn, 1, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_nu1 = np.random.normal(0, np.sqrt(variance_nu1), dust_nu1.shape)\n",
    "noise_nu2 = np.random.normal(0, np.sqrt(variance_nu2), dust_nu2.shape)\n",
    "\n",
    "noise = (noise_nu1, noise_nu2)\n",
    "\n",
    "cmb_map = utils.generate_cmb_map(n_x=nx, n_y=ny, amplitude=amplitude, spectral_index=spectral_index)\n",
    "cmb_map = cmb_map.cpu().numpy()[None, :, :]\n",
    "\n",
    "data_nu1 = dust_nu1 + noise_nu1 + cmb_map\n",
    "data_nu2 = dust_nu2 + noise_nu2 + cmb_map\n",
    "\n",
    "# define target\n",
    "data = (data_nu1, data_nu2)\n",
    "\n",
    "# target is \n",
    "image_target = data\n",
    "\n",
    "# definte initial maps for optimisation\n",
    "image_init = image_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholding = False\n",
    "if thresholding:\n",
    "    M, N, J, L = dust_nu1.shape[-2], dust_nu1.shape[-1], 7, 4\n",
    "    st_calc = denoising.Scattering2d(M, N, J, L)\n",
    "    st_calc.add_ref(ref=data_nu1)\n",
    "    s_cov = st_calc.scattering_cov(data_nu1, use_ref=True, \n",
    "                        normalization='P00', pseudo_coef=1\n",
    "                    )\n",
    "    threshold_func = denoising.threshold_func_test(s_cov)\n",
    "else:\n",
    "    threshold_func = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0021)\n",
      "tensor(0.0021)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsouros/anaconda3/envs/healpy_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#If possible, try to parallelize compute_std\n",
    "std = denoising.compute_std(image_target, contamination_arr = contamination_arr_nu1, s_cov_func=threshold_func)\n",
    "import torch\n",
    "print(torch.mean(std[0]))\n",
    "sys.exit()\n",
    "std_double = denoising.compute_std_double(image_target_nu1, image_target_nu2, contamination_arr = contamination_arr, image_ref1=image_target_nu1, image_ref2 = image_target_nu2,  wavelets='BS') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "# of estimators:  44046\n",
      "Current Loss: 1.32e+01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStarting epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     running_map \u001b[38;5;241m=\u001b[39m \u001b[43mdenoising\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenoise_double\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_target_nu1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_target_nu2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontamination_arr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontamination_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd_double\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd_double\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_init1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimage_init_nu1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_init2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimage_init_nu2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_each_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_cov_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     std_nu1 \u001b[38;5;241m=\u001b[39m denoising\u001b[38;5;241m.\u001b[39mcompute_std(running_map[\u001b[38;5;241m0\u001b[39m], contamination_arr \u001b[38;5;241m=\u001b[39m contamination_arr_nu1, s_cov_func\u001b[38;5;241m=\u001b[39mthreshold_func) \n\u001b[1;32m      9\u001b[0m     std_nu2 \u001b[38;5;241m=\u001b[39m denoising\u001b[38;5;241m.\u001b[39mcompute_std(running_map[\u001b[38;5;241m1\u001b[39m], contamination_arr \u001b[38;5;241m=\u001b[39m contamination_arr_nu2, s_cov_func\u001b[38;5;241m=\u001b[39mthreshold_func) \n",
      "File \u001b[0;32m~/Desktop/ScatteringDenoising/denoising/__init__.py:422\u001b[0m, in \u001b[0;36mdenoise_double\u001b[0;34m(target1, target2, contamination_arr, std, std_double, image_init1, image_init2, n_batch, s_cov_func, J, L, M, N, l_oversampling, frequency_factor, mode, optim_algorithm, steps, learning_rate, device, wavelets, seed, if_large_batch, C11_criteria, normalization, precision, print_each_step, Fourier, ps_bins, ps_bin_type, bi, bispectrum_bins, bispectrum_bin_type, ensemble, N_ensemble, pseudo_coef, remove_edge)\u001b[0m\n\u001b[1;32m    418\u001b[0m     squared_norms \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(normalized_diff \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m normalized_diff\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m squared_norms\u001b[38;5;241m.\u001b[39mmean()    \n\u001b[0;32m--> 422\u001b[0m image_syn \u001b[38;5;241m=\u001b[39m \u001b[43mdenoise_general_double\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m\u001b[49m\u001b[43mtarget1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_init1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_init2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBR_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m\u001b[49m\u001b[43moptim_algorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim_algorithm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_each_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_each_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m\u001b[49m\u001b[43mFourier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFourier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensemble\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensemble\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image_syn\n",
      "File \u001b[0;32m~/Desktop/ScatteringDenoising/denoising/__init__.py:542\u001b[0m, in \u001b[0;36mdenoise_general_double\u001b[0;34m(target1, target2, image_init1, image_init2, estimator_function, loss_function, mode, optim_algorithm, steps, learning_rate, device, precision, print_each_step, Fourier, ensemble)\u001b[0m\n\u001b[1;32m    540\u001b[0m t_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optim_algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLBFGS\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n",
      "File \u001b[0;32m~/anaconda3/envs/healpy_env/lib/python3.11/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/healpy_env/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/healpy_env/lib/python3.11/site-packages/torch/optim/lbfgs.py:330\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    327\u001b[0m state\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_iter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# evaluate initial f(x) and df/dx\u001b[39;00m\n\u001b[0;32m--> 330\u001b[0m orig_loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(orig_loss)\n\u001b[1;32m    332\u001b[0m current_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/healpy_env/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ScatteringDenoising/denoising/__init__.py:536\u001b[0m, in \u001b[0;36mdenoise_general_double.<locals>.closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Backpropagate the loss\u001b[39;00m\n\u001b[0;32m--> 536\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/healpy_env/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/healpy_env/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/healpy_env/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 3 #number of epochs\n",
    "image_ref = (image_target_nu1, image_target_nu2)\n",
    "# decontaminate\n",
    "for i in range(n_epochs):\n",
    "    print(f'Starting epoch {i+1}')\n",
    "    running_map = denoising.denoise_double(image_target_nu1, image_target_nu2, contamination_arr = contamination_arr, std = std, std_double=std_double, image_init1 = image_init_nu1, image_init2 = image_init_nu2, seed=0, print_each_step=True, steps = 25, n_batch = 25, s_cov_func=threshold_func)\n",
    "\n",
    "    std_nu1 = denoising.compute_std(running_map[0], contamination_arr = contamination_arr_nu1, s_cov_func=threshold_func) \n",
    "    std_nu2 = denoising.compute_std(running_map[1], contamination_arr = contamination_arr_nu2, s_cov_func=threshold_func) \n",
    "    # std_double = denoising.compute_std_double(running_map[0], running_map[1], contamination_arr = contamination_arr, image_ref1=image_target_nu1, image_ref2 = image_target_nu2) \n",
    "    # std = (std_nu1, std_nu2)\n",
    "\n",
    "image_syn_nu1 = running_map[0]\n",
    "image_syn_nu2 = running_map[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tuples to NumPy arrays\n",
    "dust = np.stack([dust_nu1[0], dust_nu2[0]])  # Shape: (2, ...)\n",
    "data = np.stack([data_nu1[0], data_nu2[0]])  # Shape: (2, ...)\n",
    "image_denoised = np.stack([image_syn_nu1[0], image_syn_nu2[0]])  # Ensure it's an array\n",
    "\n",
    "cmb = True\n",
    "noise_optimisation = False\n",
    "# Create an array of objects to preserve different shapes\n",
    "results = np.array([dust, data, image_denoised])\n",
    "np.save(f\"nu={nu}_cmb={cmb}_cross2\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "healpy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
